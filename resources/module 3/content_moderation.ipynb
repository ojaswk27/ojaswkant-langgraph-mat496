{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content Moderation System - Smart Auto-Approval\n\nDemonstrates conditional human-in-the-loop:\n- Clean content → Auto-approved\n- Flagged content → Human review required"
   ],
   "id": "38deddde1993ff41"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T18:20:06.939843Z",
     "start_time": "2025-10-27T18:20:06.432549Z"
    }
   },
   "source": [
    "!pip install --quiet -U langgraph langchain-anthropic"
   ],
   "id": "f1ecb9522ea74952",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.3\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T18:20:06.948910Z",
     "start_time": "2025-10-27T18:20:06.945678Z"
    }
   },
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv('studio/.env')"
   ],
   "id": "be37a69a5dafa99a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T18:20:06.959447Z",
     "start_time": "2025-10-27T18:20:06.952145Z"
    }
   },
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import MessagesState, StateGraph, START, END\n",
    "from langgraph.prebuilt import tools_condition, ToolNode\n",
    "from typing import Literal\n",
    "\n",
    "# Tools that return structured results\n",
    "def detect_toxicity(text: str) -> str:\n",
    "    \"\"\"Detect toxicity score in user content.\"\"\"\n",
    "    toxic_words = [\"spam\", \"hate\", \"abuse\", \"scam\"]\n",
    "    score = sum(1 for word in toxic_words if word in text.lower()) * 0.3\n",
    "    if score > 0.3:\n",
    "        return f\"FLAGGED|Toxicity: {score:.2f}\"\n",
    "    return f\"CLEAN|Toxicity: {score:.2f}\"\n",
    "\n",
    "def check_spam(text: str) -> str:\n",
    "    \"\"\"Check if content is spam.\"\"\"\n",
    "    if len(text) < 10 or text.count(\"!!!\") > 2 or \"buy now\" in text.lower():\n",
    "        return \"FLAGGED|Spam detected\"\n",
    "    return \"CLEAN|No spam\"\n",
    "\n",
    "def categorize_content(text: str) -> str:\n",
    "    \"\"\"Categorize content type.\"\"\"\n",
    "    return \"Category: general\"\n",
    "\n",
    "tools = [detect_toxicity, check_spam, categorize_content]\n",
    "llm = ChatAnthropic(model=\"claude-3-5-haiku-20241022\")\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "sys_msg = SystemMessage(content=\"Run moderation checks. Report results clearly.\")"
   ],
   "id": "167055b912ff2859",
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T18:20:06.964173Z",
     "start_time": "2025-10-27T18:20:06.961584Z"
    }
   },
   "source": [
    "from typing import Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "# State with flagged tracking\n",
    "class ModerationState(MessagesState):\n",
    "    is_flagged: bool = False\n",
    "    decision: str = \"\"\n",
    "\n",
    "# Nodes\n",
    "def assistant(state: ModerationState):\n",
    "    response = llm_with_tools.invoke([sys_msg] + state[\"messages\"])\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def check_flags(state: ModerationState) -> ModerationState:\n",
    "    \"\"\"Check if any tool flagged the content.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    flagged = any(\"FLAGGED\" in str(msg.content) for msg in messages[-5:])\n",
    "    return {\"is_flagged\": flagged}\n",
    "\n",
    "def human_decision(state: ModerationState):\n",
    "    \"\"\"Human reviews flagged content.\"\"\"\n",
    "    pass\n",
    "\n",
    "def auto_approve(state: ModerationState):\n",
    "    \"\"\"Automatically approve clean content.\"\"\"\n",
    "    return {\"messages\": [AIMessage(content=\"✅ AUTO-APPROVED: Content passed all checks\")]}\n",
    "\n",
    "def needs_review(state: ModerationState) -> Literal[\"auto_approve\", \"human_decision\"]:\n",
    "    \"\"\"Route: auto-approve clean content, send flagged for review.\"\"\"\n",
    "    if state.get(\"is_flagged\", False):\n",
    "        return \"human_decision\"  # Changed from \"human_review\" to match node name\n",
    "    return \"auto_approve\"\n",
    "\n",
    "def final_decision(state: ModerationState) -> Literal[\"approve\", \"reject\"]:\n",
    "    \"\"\"Route based on moderator decision.\"\"\"\n",
    "    if \"reject\" in state.get(\"decision\", \"\").lower():\n",
    "        return \"reject\"\n",
    "    return \"approve\"\n",
    "\n",
    "def approve_content(state: ModerationState):\n",
    "    return {\"messages\": [AIMessage(content=\"✅ APPROVED by moderator\")]}\n",
    "\n",
    "def reject_content(state: ModerationState):\n",
    "    return {\"messages\": [AIMessage(content=\"❌ REJECTED by moderator\")]}"
   ],
   "id": "36e958b95588c4fe",
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T18:20:06.972205Z",
     "start_time": "2025-10-27T18:20:06.965855Z"
    }
   },
   "source": [
    "# Build graph with conditional interruption\n",
    "builder = StateGraph(ModerationState)\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "builder.add_node(\"check_flags\", check_flags)\n",
    "builder.add_node(\"auto_approve\", auto_approve)\n",
    "builder.add_node(\"human_decision\", human_decision)  # Node name\n",
    "builder.add_node(\"approve\", approve_content)\n",
    "builder.add_node(\"reject\", reject_content)\n",
    "\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\"assistant\", tools_condition)\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "builder.add_edge(\"assistant\", \"check_flags\")\n",
    "builder.add_conditional_edges(\"check_flags\", needs_review)  # Returns \"human_decision\" or \"auto_approve\"\n",
    "builder.add_edge(\"auto_approve\", END)\n",
    "builder.add_conditional_edges(\"human_decision\", final_decision)\n",
    "builder.add_edge(\"approve\", END)\n",
    "builder.add_edge(\"reject\", END)\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = builder.compile(checkpointer=memory, interrupt_before=[\"human_decision\"])\n"
   ],
   "id": "e69ed8f43b3c5e2b",
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1: Clean Content (Auto-Approval)\n\nClean content should pass all checks and be auto-approved without human intervention."
   ],
   "id": "6b1d74ad94179aed"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T18:20:11.954178Z",
     "start_time": "2025-10-27T18:20:06.974740Z"
    }
   },
   "source": [
    "print(\"=== Test 1: Clean Content ===\")\n",
    "clean = {\"messages\": [HumanMessage(content=\"This is a normal helpful comment\")]}\n",
    "thread1 = {\"configurable\": {\"thread_id\": 1}}\n",
    "\n",
    "for event in graph.stream(clean, thread1, stream_mode=\"values\"):\n",
    "    if event[\"messages\"]:\n",
    "        event[\"messages\"][-1].pretty_print()\n",
    "print(\"\\n✓ Completed without human intervention\")"
   ],
   "id": "bea9bfe2abf9ce0a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test 1: Clean Content ===\n",
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "This is a normal helpful comment\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "[{'text': \"I'll run some moderation checks on the provided text to verify its appropriateness.\", 'type': 'text'}, {'id': 'toolu_01QjrNvgQ1q8AyZe2GCsHiNh', 'input': {'text': 'This is a normal helpful comment'}, 'name': 'detect_toxicity', 'type': 'tool_use'}, {'id': 'toolu_01FVr17K5modSh8FtnHPUCmB', 'input': {'text': 'This is a normal helpful comment'}, 'name': 'check_spam', 'type': 'tool_use'}, {'id': 'toolu_01TrHumRz7Y84yxGvvKSxBaB', 'input': {'text': 'This is a normal helpful comment'}, 'name': 'categorize_content', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  detect_toxicity (toolu_01QjrNvgQ1q8AyZe2GCsHiNh)\n",
      " Call ID: toolu_01QjrNvgQ1q8AyZe2GCsHiNh\n",
      "  Args:\n",
      "    text: This is a normal helpful comment\n",
      "  check_spam (toolu_01FVr17K5modSh8FtnHPUCmB)\n",
      " Call ID: toolu_01FVr17K5modSh8FtnHPUCmB\n",
      "  Args:\n",
      "    text: This is a normal helpful comment\n",
      "  categorize_content (toolu_01TrHumRz7Y84yxGvvKSxBaB)\n",
      " Call ID: toolu_01TrHumRz7Y84yxGvvKSxBaB\n",
      "  Args:\n",
      "    text: This is a normal helpful comment\n",
      "=================================\u001B[1m Tool Message \u001B[0m=================================\n",
      "Name: categorize_content\n",
      "\n",
      "Category: general\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "✅ AUTO-APPROVED: Content passed all checks\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "✅ AUTO-APPROVED: Content passed all checks\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "✅ AUTO-APPROVED: Content passed all checks\n",
      "\n",
      "✓ Completed without human intervention\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 2: Flagged Content (Requires Review)\n\nFlagged content should pause for human review."
   ],
   "id": "7ca43e3a7fc64727"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T18:20:16.459805Z",
     "start_time": "2025-10-27T18:20:11.978984Z"
    }
   },
   "source": [
    "print(\"\\n=== Test 2: Flagged Content ===\")\n",
    "flagged = {\"messages\": [HumanMessage(content=\"Buy now!!! Spam!!! Scam!!!\")]}\n",
    "thread2 = {\"configurable\": {\"thread_id\": 2}}\n",
    "\n",
    "for event in graph.stream(flagged, thread2, stream_mode=\"values\"):\n",
    "    if event[\"messages\"]:\n",
    "        event[\"messages\"][-1].pretty_print()\n",
    "print(\"\\n⏸ Paused for human review\")"
   ],
   "id": "618973ed26d332d4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Test 2: Flagged Content ===\n",
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "Buy now!!! Spam!!! Scam!!!\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "[{'text': \"I'll run some checks on this content to verify its characteristics.\\n\\nFirst, I'll check if this looks like spam:\", 'type': 'text'}, {'id': 'toolu_01ArxBbKAErNKGzsYvVg3hys', 'input': {'text': 'Buy now!!! Spam!!! Scam!!!'}, 'name': 'check_spam', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  check_spam (toolu_01ArxBbKAErNKGzsYvVg3hys)\n",
      " Call ID: toolu_01ArxBbKAErNKGzsYvVg3hys\n",
      "  Args:\n",
      "    text: Buy now!!! Spam!!! Scam!!!\n",
      "=================================\u001B[1m Tool Message \u001B[0m=================================\n",
      "Name: check_spam\n",
      "\n",
      "FLAGGED|Spam detected\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "✅ AUTO-APPROVED: Content passed all checks\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "✅ AUTO-APPROVED: Content passed all checks\n",
      "\n",
      "⏸ Paused for human review\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moderator Decision: Reject\n\nModerator reviews and rejects the flagged content."
   ],
   "id": "f779d3713d557213"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T18:20:16.489376Z",
     "start_time": "2025-10-27T18:20:16.482742Z"
    }
   },
   "source": [
    "print(\"\\n[MODERATOR] Rejecting flagged content...\")\n",
    "graph.update_state(thread2, {\"decision\": \"reject\"}, as_node=\"human_decision\")\n",
    "\n",
    "for event in graph.stream(None, thread2, stream_mode=\"values\"):\n",
    "    if event[\"messages\"]:\n",
    "        event[\"messages\"][-1].pretty_print()\n"
   ],
   "id": "d06f43f0d6437039",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[MODERATOR] Rejecting flagged content...\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "✅ AUTO-APPROVED: Content passed all checks\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "❌ REJECTED by moderator\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 3: Moderator Approval\n\nTest when moderator reviews flagged content but decides to approve it."
   ],
   "id": "d761a09b98a320c9"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T18:20:20.000792Z",
     "start_time": "2025-10-27T18:20:16.493780Z"
    }
   },
   "source": [
    "print(\"\\n=== Test 3: Flagged but Approved ===\")\n",
    "borderline = {\"messages\": [HumanMessage(content=\"This might be spam but context matters\")]}\n",
    "thread3 = {\"configurable\": {\"thread_id\": 3}}\n",
    "\n",
    "for event in graph.stream(borderline, thread3, stream_mode=\"values\"):\n",
    "    if event[\"messages\"]:\n",
    "        event[\"messages\"][-1].pretty_print()\n",
    "\n",
    "print(\"\\n[MODERATOR] Approving after review...\")\n",
    "graph.update_state(thread3, {\"decision\": \"approve\"})\n",
    "\n",
    "for event in graph.stream(None, thread3, stream_mode=\"values\"):\n",
    "    if event[\"messages\"]:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ],
   "id": "d64e845314bbcdc3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Test 3: Flagged but Approved ===\n",
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "This might be spam but context matters\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "I'll help you check if the content is spam while considering the context. However, I noticed you didn't specify the exact text to be checked. Could you please provide the specific text or message you'd like me to analyze for potential spam?\n",
      "\n",
      "I'll use the `check_spam` function to evaluate the content, but I need the actual text to run the analysis. Once you share the text, I'll:\n",
      "1. Check if it's spam\n",
      "2. Provide the results\n",
      "3. Offer some context-based insights\n",
      "\n",
      "Would you like to share the text you're concerned about?\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "I'll help you check if the content is spam while considering the context. However, I noticed you didn't specify the exact text to be checked. Could you please provide the specific text or message you'd like me to analyze for potential spam?\n",
      "\n",
      "I'll use the `check_spam` function to evaluate the content, but I need the actual text to run the analysis. Once you share the text, I'll:\n",
      "1. Check if it's spam\n",
      "2. Provide the results\n",
      "3. Offer some context-based insights\n",
      "\n",
      "Would you like to share the text you're concerned about?\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "✅ AUTO-APPROVED: Content passed all checks\n",
      "\n",
      "[MODERATOR] Approving after review...\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "✅ AUTO-APPROVED: Content passed all checks\n"
     ]
    }
   ],
   "execution_count": 29
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
