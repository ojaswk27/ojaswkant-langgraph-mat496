{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhanced Research Assistant\n",
    "\n",
    "## Improvements:\n",
    "### Better Sources:\n",
    "- **Semantic Scholar API** - Academic papers without PDF dependencies\n",
    "- **DuckDuckGo** - Additional web search\n",
    "- **Tavily** - High-quality web results\n",
    "- **Source quality filtering** - Removes low-quality results\n",
    "\n",
    "### Output Quality:\n",
    "- **Fact-checking step** - Verifies claims across sources\n",
    "- **Executive summary** - Concise 3-5 sentence overview\n",
    "- **Citation verification** - Ensures all citations are valid\n",
    "- **Source diversity scoring** - Tracks source types used"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T18:04:03.893968Z",
     "start_time": "2025-10-31T18:04:02.328302Z"
    }
   },
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langgraph langchain_anthropic langchain_community langchain_core tavily-python duckduckgo-search"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T18:04:03.904876Z",
     "start_time": "2025-10-31T18:04:03.898163Z"
    }
   },
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv('studio/.env')"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T18:04:04.242506Z",
     "start_time": "2025-10-31T18:04:03.916185Z"
    }
   },
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "# Use Haiku for cost-efficiency\n",
    "llm = ChatAnthropic(model=\"claude-haiku-4-5-20251001\", temperature=0)\n",
    "\n",
    "# Optional: Use Sonnet for complex reasoning tasks\n",
    "# llm_sonnet = ChatAnthropic(model=\"claude-sonnet-4-5-20250929\", temperature=0)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T18:04:04.329768Z",
     "start_time": "2025-10-31T18:04:04.247350Z"
    }
   },
   "source": [
    "_set_env(\"LANGSMITH_API_KEY\")\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"research-assistant-enhanced\""
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_set_env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43m_set_env\u001B[49m(\u001B[33m\"\u001B[39m\u001B[33mLANGSMITH_API_KEY\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m      2\u001B[39m os.environ[\u001B[33m\"\u001B[39m\u001B[33mLANGSMITH_TRACING\u001B[39m\u001B[33m\"\u001B[39m] = \u001B[33m\"\u001B[39m\u001B[33mtrue\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m      3\u001B[39m os.environ[\u001B[33m\"\u001B[39m\u001B[33mLANGSMITH_PROJECT\u001B[39m\u001B[33m\"\u001B[39m] = \u001B[33m\"\u001B[39m\u001B[33mresearch-assistant-enhanced\u001B[39m\u001B[33m\"\u001B[39m\n",
      "\u001B[31mNameError\u001B[39m: name '_set_env' is not defined"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schema Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import List, Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Analyst(BaseModel):\n",
    "    affiliation: str = Field(description=\"Primary affiliation of the analyst.\")\n",
    "    name: str = Field(description=\"Name of the analyst.\")\n",
    "    role: str = Field(description=\"Role of the analyst in the context of the topic.\")\n",
    "    description: str = Field(description=\"Description of the analyst focus, concerns, and motives.\")\n",
    "    \n",
    "    @property\n",
    "    def persona(self) -> str:\n",
    "        return f\"Name: {self.name}\\nRole: {self.role}\\nAffiliation: {self.affiliation}\\nDescription: {self.description}\\n\"\n",
    "\n",
    "class Perspectives(BaseModel):\n",
    "    analysts: List[Analyst] = Field(description=\"Comprehensive list of analysts with their roles and affiliations.\")\n",
    "\n",
    "class GenerateAnalystsState(TypedDict):\n",
    "    topic: str\n",
    "    max_analysts: int\n",
    "    human_analyst_feedback: str\n",
    "    analysts: List[Analyst]\n",
    "\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "class InterviewState(MessagesState):\n",
    "    max_num_turns: int\n",
    "    context: Annotated[list, operator.add]\n",
    "    analyst: Analyst\n",
    "    interview: str\n",
    "    sections: list\n",
    "\n",
    "class SearchQuery(BaseModel):\n",
    "    search_query: str = Field(None, description=\"Search query for retrieval.\")\n",
    "\n",
    "class ResearchGraphState(TypedDict):\n",
    "    topic: str\n",
    "    max_analysts: int\n",
    "    human_analyst_feedback: str\n",
    "    analysts: List[Analyst]\n",
    "    sections: Annotated[list, operator.add]\n",
    "    introduction: str\n",
    "    content: str\n",
    "    conclusion: str\n",
    "    executive_summary: str  # NEW\n",
    "    final_report: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enhanced Search Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search instructions\n",
    "search_instructions = SystemMessage(content=\"\"\"You will be given a conversation between an analyst and an expert.\n",
    "\n",
    "Your goal is to generate a well-structured query for use in retrieval and/or web-search related to the conversation.\n",
    "        \n",
    "First, analyze the full conversation.\n",
    "Pay particular attention to the final question posed by the analyst.\n",
    "Convert this final question into a well-structured web search query\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tavily search\n",
    "from langchain_tavily import TavilySearch\n",
    "\n",
    "def search_tavily(state: InterviewState):\n",
    "    \"\"\"Search Tavily for high-quality web results\"\"\"\n",
    "    tavily_search = TavilySearch(max_results=3)\n",
    "    \n",
    "    structured_llm = llm.with_structured_output(SearchQuery)\n",
    "    search_query = structured_llm.invoke([search_instructions] + state['messages'])\n",
    "    \n",
    "    data = tavily_search.invoke({\"query\": search_query.search_query})\n",
    "    search_docs = data.get(\"results\", data)\n",
    "    \n",
    "    # Format with quality score if available\n",
    "    formatted_docs = \"\\n\\n---\\n\\n\".join([\n",
    "        f'<Document href=\"{doc[\"url\"]}\" score=\"{doc.get(\"score\", \"N/A\")}\"/>\\n{doc[\"content\"]}\\n</Document>'\n",
    "        for doc in search_docs\n",
    "    ])\n",
    "    \n",
    "    return {\"context\": [formatted_docs]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DuckDuckGo search\n",
    "from duckduckgo_search import DDGS\n",
    "\n",
    "def search_duckduckgo(state: InterviewState):\n",
    "    \"\"\"Search DuckDuckGo for additional web results\"\"\"\n",
    "    structured_llm = llm.with_structured_output(SearchQuery)\n",
    "    search_query = structured_llm.invoke([search_instructions] + state['messages'])\n",
    "    \n",
    "    try:\n",
    "        with DDGS() as ddgs:\n",
    "            results = list(ddgs.text(search_query.search_query, max_results=3))\n",
    "        \n",
    "        formatted_docs = \"\\n\\n---\\n\\n\".join([\n",
    "            f'<Document href=\"{doc[\"href\"]}\"/>\\n{doc[\"body\"]}\\n</Document>'\n",
    "            for doc in results\n",
    "        ])\n",
    "    except Exception as e:\n",
    "        formatted_docs = f\"DuckDuckGo search failed: {str(e)}\"\n",
    "    \n",
    "    return {\"context\": [formatted_docs]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Semantic Scholar search (no PDF dependencies!)\n",
    "import requests\n",
    "\n",
    "def search_semantic_scholar(state: InterviewState):\n",
    "    \"\"\"Search Semantic Scholar for academic papers\"\"\"\n",
    "    structured_llm = llm.with_structured_output(SearchQuery)\n",
    "    search_query = structured_llm.invoke([search_instructions] + state['messages'])\n",
    "    \n",
    "    try:\n",
    "        url = \"https://api.semanticscholar.org/graph/v1/paper/search\"\n",
    "        params = {\n",
    "            \"query\": search_query.search_query,\n",
    "            \"limit\": 3,\n",
    "            \"fields\": \"title,abstract,year,authors,citationCount,url,paperId\"\n",
    "        }\n",
    "        \n",
    "        response = requests.get(url, params=params, timeout=10)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            papers = data.get(\"data\", [])\n",
    "            \n",
    "            # Filter for quality: require abstract and citations\n",
    "            quality_papers = [\n",
    "                p for p in papers \n",
    "                if p.get('abstract') and (p.get('citationCount', 0) > 5 or p.get('year', 0) >= 2020)\n",
    "            ]\n",
    "            \n",
    "            formatted_docs = \"\\n\\n---\\n\\n\".join([\n",
    "                f'<Document source=\"academic\" '\n",
    "                f'title=\"{paper.get(\"title\", \"\")}\" '\n",
    "                f'year=\"{paper.get(\"year\", \"\")}\" '\n",
    "                f'citations=\"{paper.get(\"citationCount\", 0)}\" '\n",
    "                f'url=\"https://www.semanticscholar.org/paper/{paper.get(\"paperId\", \"\")}\"/>\\n'\n",
    "                f'{paper.get(\"abstract\", \"\")}\\n'\n",
    "                f'Authors: {\", \".join([a.get(\"name\", \"\") for a in paper.get(\"authors\", [])][:3])}\\n'\n",
    "                f'</Document>'\n",
    "                for paper in quality_papers[:3]\n",
    "            ])\n",
    "        else:\n",
    "            formatted_docs = f\"Semantic Scholar search returned status {response.status_code}\"\n",
    "    except Exception as e:\n",
    "        formatted_docs = f\"Semantic Scholar search failed: {str(e)}\"\n",
    "    \n",
    "    return {\"context\": [formatted_docs]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interview Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate analyst question\n",
    "question_instructions = \"\"\"You are an analyst tasked with interviewing an expert to learn about a specific topic.\n",
    "\n",
    "Your goal is boil down to interesting and specific insights related to your topic.\n",
    "\n",
    "1. Interesting: Insights that people will find surprising or non-obvious.\n",
    "2. Specific: Insights that avoid generalities and include specific examples from the expert.\n",
    "\n",
    "Here is your topic of focus and set of goals: {goals}\n",
    "        \n",
    "Begin by introducing yourself using a name that fits your persona, and then ask your question.\n",
    "\n",
    "Continue to ask questions to drill down and refine your understanding of the topic.\n",
    "        \n",
    "When you are satisfied with your understanding, complete the interview with: \"Thank you so much for your help!\"\n",
    "\n",
    "Remember to stay in character throughout your response, reflecting the persona and goals provided to you.\"\"\"\n",
    "\n",
    "def generate_question(state: InterviewState):\n",
    "    \"\"\"Node to generate a question\"\"\"\n",
    "    analyst = state[\"analyst\"]\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    system_message = question_instructions.format(goals=analyst.persona)\n",
    "    question = llm.invoke([SystemMessage(content=system_message)] + messages)\n",
    "    \n",
    "    return {\"messages\": [question]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate expert answer\n",
    "answer_instructions = \"\"\"You are an expert being interviewed by an analyst.\n",
    "\n",
    "Here is analyst area of focus: {goals}\n",
    "        \n",
    "You goal is to answer a question posed by the interviewer.\n",
    "\n",
    "To answer question, use this context:\n",
    "        \n",
    "{context}\n",
    "\n",
    "When answering questions, follow these guidelines:\n",
    "        \n",
    "1. Use only the information provided in the context.\n",
    "2. Do not introduce external information or make assumptions beyond what is explicitly stated in the context.\n",
    "3. The context includes sources with metadata like relevance scores and citation counts. Prioritize highly cited or recent sources.\n",
    "4. If the answer is not in the context, simply state: \"I don't have enough information to answer that.\"\n",
    "5. Be direct and concise, providing specific details from the sources.\n",
    "6. Conclude your response by saying: \"Do you have any other questions?\"\"\"\n",
    "\n",
    "def generate_answer(state: InterviewState):\n",
    "    \"\"\"Node to answer a question\"\"\"\n",
    "    analyst = state[\"analyst\"]\n",
    "    messages = state[\"messages\"]\n",
    "    context = state[\"context\"]\n",
    "    \n",
    "    system_message = answer_instructions.format(goals=analyst.persona, context=context)\n",
    "    answer = llm.invoke([SystemMessage(content=system_message)] + messages)\n",
    "    \n",
    "    return {\"messages\": [answer]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save interview\n",
    "from langchain_core.messages import get_buffer_string\n",
    "\n",
    "def save_interview(state: InterviewState):\n",
    "    \"\"\"Node to save the interview\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    interview = get_buffer_string(messages)\n",
    "    return {\"interview\": interview}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Route messages\n",
    "def route_messages(state: InterviewState, max_num_turns: int = 3):\n",
    "    \"\"\"Route between question and end based on turn count\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    num_responses = len([m for m in messages if isinstance(m, AIMessage)])\n",
    "    \n",
    "    # Check if expert said thank you (interview complete)\n",
    "    if num_responses >= max_num_turns:\n",
    "        return 'save_interview'\n",
    "    \n",
    "    last_message = messages[-1]\n",
    "    if \"Thank you so much for your help\" in last_message.content:\n",
    "        return 'save_interview'\n",
    "    \n",
    "    return 'ask_question'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write section with citations\n",
    "section_writer_instructions = \"\"\"You are an expert technical writer drafting a section of a report.\n",
    "\n",
    "Your focus: {focus}\n",
    "\n",
    "Use the following source materials:\n",
    "\n",
    "{context}\n",
    "\n",
    "Guidelines:\n",
    "1. Write a detailed, well-structured section (200-400 words)\n",
    "2. Use markdown formatting with ## for the section header\n",
    "3. Include specific facts and figures from sources\n",
    "4. Cite sources using [1], [2], etc. - place citation immediately after the relevant claim\n",
    "5. Prioritize academic sources (higher citation counts) and recent information\n",
    "6. At the end, list all sources used:\n",
    "\n",
    "## Sources\n",
    "[1] Source URL or reference\n",
    "[2] Source URL or reference\n",
    "\n",
    "7. Only cite sources that directly support specific claims\n",
    "8. Never create fake citations\"\"\"\n",
    "\n",
    "def write_section(state: InterviewState):\n",
    "    \"\"\"Node to write a section\"\"\"\n",
    "    interview = state[\"interview\"]\n",
    "    context = state[\"context\"]\n",
    "    analyst = state[\"analyst\"]\n",
    "    \n",
    "    system_message = section_writer_instructions.format(\n",
    "        focus=analyst.description,\n",
    "        context=context\n",
    "    )\n",
    "    section = llm.invoke([\n",
    "        SystemMessage(content=system_message),\n",
    "        HumanMessage(content=f\"Use this interview transcript to write your section: {interview}\")\n",
    "    ])\n",
    "    \n",
    "    return {\"sections\": [section.content]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Interview Sub-graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END, START\n",
    "\n",
    "# Create interview sub-graph\n",
    "interview_builder = StateGraph(InterviewState)\n",
    "interview_builder.add_node(\"ask_question\", generate_question)\n",
    "interview_builder.add_node(\"search_tavily\", search_tavily)\n",
    "interview_builder.add_node(\"search_duckduckgo\", search_duckduckgo)\n",
    "interview_builder.add_node(\"search_semantic_scholar\", search_semantic_scholar)\n",
    "interview_builder.add_node(\"answer_question\", generate_answer)\n",
    "interview_builder.add_node(\"save_interview\", save_interview)\n",
    "interview_builder.add_node(\"write_section\", write_section)\n",
    "\n",
    "# Flow - parallel search execution\n",
    "interview_builder.add_edge(START, \"ask_question\")\n",
    "interview_builder.add_edge(\"ask_question\", \"search_tavily\")\n",
    "interview_builder.add_edge(\"ask_question\", \"search_duckduckgo\")\n",
    "interview_builder.add_edge(\"ask_question\", \"search_semantic_scholar\")\n",
    "interview_builder.add_edge(\"search_tavily\", \"answer_question\")\n",
    "interview_builder.add_edge(\"search_duckduckgo\", \"answer_question\")\n",
    "interview_builder.add_edge(\"search_semantic_scholar\", \"answer_question\")\n",
    "interview_builder.add_conditional_edges(\n",
    "    \"answer_question\",\n",
    "    route_messages,\n",
    "    ['ask_question', 'save_interview']\n",
    ")\n",
    "interview_builder.add_edge(\"save_interview\", \"write_section\")\n",
    "interview_builder.add_edge(\"write_section\", END)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyst Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyst_instructions = \"\"\"You are tasked with creating a set of AI analyst personas. Follow these instructions carefully:\n",
    "\n",
    "1. First, review the research topic:\n",
    "{topic}\n",
    "        \n",
    "2. Examine any editorial feedback that has been optionally provided to guide creation of the analysts:\n",
    "        \n",
    "{human_analyst_feedback}\n",
    "    \n",
    "3. Determine the most interesting themes based upon documents and/or feedback above.\n",
    "                    \n",
    "4. Pick the top {max_analysts} themes.\n",
    "\n",
    "5. Assign one analyst to each theme.\"\"\"\n",
    "\n",
    "def create_analysts(state: GenerateAnalystsState):\n",
    "    \"\"\"Create analysts\"\"\"\n",
    "    topic = state['topic']\n",
    "    max_analysts = state['max_analysts']\n",
    "    human_analyst_feedback = state.get('human_analyst_feedback', '')\n",
    "    \n",
    "    structured_llm = llm.with_structured_output(Perspectives)\n",
    "    \n",
    "    system_message = analyst_instructions.format(\n",
    "        topic=topic,\n",
    "        human_analyst_feedback=human_analyst_feedback,\n",
    "        max_analysts=max_analysts\n",
    "    )\n",
    "    \n",
    "    analysts = structured_llm.invoke([\n",
    "        SystemMessage(content=system_message),\n",
    "        HumanMessage(content=\"Generate the set of analysts.\")\n",
    "    ])\n",
    "    \n",
    "    return {\"analysts\": analysts.analysts}\n",
    "\n",
    "def human_feedback(state: GenerateAnalystsState):\n",
    "    \"\"\"No-op node that should be interrupted on\"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report Writing with Quality Enhancements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fact-checking step\n",
    "fact_check_instructions = \"\"\"You are a fact-checker reviewing a research report section.\n",
    "\n",
    "Section to check:\n",
    "{section}\n",
    "\n",
    "All source materials:\n",
    "{all_sources}\n",
    "\n",
    "Your task:\n",
    "1. Identify any claims that seem unsupported by the sources\n",
    "2. Check if citations [1], [2], etc. actually exist in the source list\n",
    "3. Flag any potential inaccuracies or overgeneralizations\n",
    "4. Verify numbers and statistics match the sources\n",
    "\n",
    "Return either:\n",
    "- \"VERIFIED\" if all claims are properly supported\n",
    "- A list of specific issues found (max 3 most important)\n",
    "\n",
    "Be concise and specific.\"\"\"\n",
    "\n",
    "def fact_check_sections(sections: List[str]) -> str:\n",
    "    \"\"\"Fact-check report sections\"\"\"\n",
    "    # Extract all sources from sections\n",
    "    all_sources = \"\\n\".join([\n",
    "        s.split(\"## Sources\")[1] if \"## Sources\" in s else \"\"\n",
    "        for s in sections\n",
    "    ])\n",
    "    \n",
    "    issues = []\n",
    "    for i, section in enumerate(sections):\n",
    "        system_message = fact_check_instructions.format(\n",
    "            section=section,\n",
    "            all_sources=all_sources\n",
    "        )\n",
    "        result = llm.invoke([\n",
    "            SystemMessage(content=system_message),\n",
    "            HumanMessage(content=\"Check this section.\")\n",
    "        ])\n",
    "        \n",
    "        if result.content.strip() != \"VERIFIED\":\n",
    "            issues.append(f\"Section {i+1}: {result.content}\")\n",
    "    \n",
    "    return \"\\n\\n\".join(issues) if issues else \"All sections verified\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report writing\n",
    "report_writer_instructions = \"\"\"You are a technical writer creating a report on this overall topic:\n",
    "\n",
    "{topic}\n",
    "    \n",
    "You have a team of analysts. Each analyst has done two things:\n",
    "1. They conducted an interview with an expert on a specific sub-topic.\n",
    "2. They write up their finding into a memo.\n",
    "\n",
    "Your task:\n",
    "1. You will be given a collection of memos from your analysts.\n",
    "2. Think carefully about the insights from each memo.\n",
    "3. Consolidate these into a crisp overall summary that ties together the central ideas from all of the memos.\n",
    "4. Summarize the central points in each memo into a cohesive single narrative.\n",
    "\n",
    "To format your report:\n",
    "1. Use markdown formatting.\n",
    "2. Include no pre-amble for the report.\n",
    "3. Use no sub-heading.\n",
    "4. Start your report with a single title header: ## Insights\n",
    "5. Do not mention any analyst names in your report.\n",
    "6. Preserve any citations in the memos, which will be annotated in brackets, for example [1] or [2].\n",
    "7. Create a final, consolidated list of sources and add to a Sources section with the `## Sources` header.\n",
    "8. List your sources in order and do not repeat.\n",
    "\n",
    "Here are the memos from your analysts to build your report from:\n",
    "\n",
    "{context}\n",
    "\n",
    "Fact-check results:\n",
    "{fact_check_results}\"\"\"\n",
    "\n",
    "def write_report(state: ResearchGraphState):\n",
    "    \"\"\"Node to write the final report body\"\"\"\n",
    "    sections = state[\"sections\"]\n",
    "    topic = state[\"topic\"]\n",
    "    \n",
    "    # Run fact-checking\n",
    "    fact_check_results = fact_check_sections(sections)\n",
    "    \n",
    "    formatted_str_sections = \"\\n\\n\".join([f\"{section}\" for section in sections])\n",
    "    \n",
    "    system_message = report_writer_instructions.format(\n",
    "        topic=topic,\n",
    "        context=formatted_str_sections,\n",
    "        fact_check_results=fact_check_results\n",
    "    )\n",
    "    report = llm.invoke([\n",
    "        SystemMessage(content=system_message),\n",
    "        HumanMessage(content=\"Write a report based upon these memos.\")\n",
    "    ])\n",
    "    \n",
    "    return {\"content\": report.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduction and conclusion\n",
    "intro_conclusion_instructions = \"\"\"You are a technical writer finishing a report on {topic}\n",
    "\n",
    "You will be given all of the sections of the report.\n",
    "\n",
    "You job is to write a crisp and compelling introduction or conclusion section.\n",
    "\n",
    "The user will instruct you whether to write the introduction or conclusion.\n",
    "\n",
    "Include no pre-amble for either section.\n",
    "\n",
    "Target around 100 words, crisply previewing (for introduction) or recapping (for conclusion) all of the sections of the report.\n",
    "\n",
    "Use markdown formatting.\n",
    "\n",
    "For your introduction, create a compelling title and use the # header for the title.\n",
    "For your introduction, use ## Introduction as the section header.\n",
    "For your conclusion, use ## Conclusion as the section header.\n",
    "\n",
    "Here are the sections to reflect on for writing: {formatted_str_sections}\"\"\"\n",
    "\n",
    "def write_introduction(state: ResearchGraphState):\n",
    "    sections = state[\"sections\"]\n",
    "    topic = state[\"topic\"]\n",
    "    formatted_str_sections = \"\\n\\n\".join([f\"{section}\" for section in sections])\n",
    "    \n",
    "    instructions = intro_conclusion_instructions.format(\n",
    "        topic=topic,\n",
    "        formatted_str_sections=formatted_str_sections\n",
    "    )\n",
    "    intro = llm.invoke([instructions, HumanMessage(content=\"Write the report introduction\")])\n",
    "    return {\"introduction\": intro.content}\n",
    "\n",
    "def write_conclusion(state: ResearchGraphState):\n",
    "    sections = state[\"sections\"]\n",
    "    topic = state[\"topic\"]\n",
    "    formatted_str_sections = \"\\n\\n\".join([f\"{section}\" for section in sections])\n",
    "    \n",
    "    instructions = intro_conclusion_instructions.format(\n",
    "        topic=topic,\n",
    "        formatted_str_sections=formatted_str_sections\n",
    "    )\n",
    "    conclusion = llm.invoke([instructions, HumanMessage(content=\"Write the report conclusion\")])\n",
    "    return {\"conclusion\": conclusion.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW: Executive summary\n",
    "executive_summary_instructions = \"\"\"You are a technical writer creating an executive summary.\n",
    "\n",
    "Topic: {topic}\n",
    "\n",
    "Full report content:\n",
    "{content}\n",
    "\n",
    "Create a 3-5 sentence executive summary that:\n",
    "1. Captures the most critical findings\n",
    "2. Is written for C-level executives (non-technical)\n",
    "3. Highlights actionable insights\n",
    "4. Uses clear, concise language\n",
    "\n",
    "Format: Use ## Executive Summary as header, then the summary.\"\"\"\n",
    "\n",
    "def write_executive_summary(state: ResearchGraphState):\n",
    "    \"\"\"Generate executive summary\"\"\"\n",
    "    content = state[\"content\"]\n",
    "    topic = state[\"topic\"]\n",
    "    \n",
    "    instructions = executive_summary_instructions.format(\n",
    "        topic=topic,\n",
    "        content=content\n",
    "    )\n",
    "    summary = llm.invoke([\n",
    "        SystemMessage(content=instructions),\n",
    "        HumanMessage(content=\"Write the executive summary.\")\n",
    "    ])\n",
    "    \n",
    "    return {\"executive_summary\": summary.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finalize report\n",
    "def finalize_report(state: ResearchGraphState):\n",
    "    \"\"\"Assemble final report\"\"\"\n",
    "    content = state[\"content\"]\n",
    "    \n",
    "    # Clean up content\n",
    "    if content.startswith(\"## Insights\"):\n",
    "        content = content.replace(\"## Insights\", \"\").strip()\n",
    "    \n",
    "    # Split content and sources\n",
    "    if \"## Sources\" in content:\n",
    "        try:\n",
    "            content, sources = content.split(\"\\n## Sources\\n\")\n",
    "        except:\n",
    "            sources = None\n",
    "    else:\n",
    "        sources = None\n",
    "    \n",
    "    # Assemble report\n",
    "    final_report = (\n",
    "        state[\"introduction\"] + \"\\n\\n\" +\n",
    "        state.get(\"executive_summary\", \"\") + \"\\n\\n---\\n\\n\" +\n",
    "        content + \"\\n\\n---\\n\\n\" +\n",
    "        state[\"conclusion\"]\n",
    "    )\n",
    "    \n",
    "    if sources:\n",
    "        final_report += \"\\n\\n## Sources\\n\" + sources\n",
    "    \n",
    "    return {\"final_report\": final_report}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Main Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.constants import Send\n",
    "\n",
    "def initiate_all_interviews(state: ResearchGraphState):\n",
    "    \"\"\"Conditional edge to initiate all interviews via Send() API or return to create_analysts\"\"\"\n",
    "    human_analyst_feedback = state.get('human_analyst_feedback', 'approve')\n",
    "    \n",
    "    if human_analyst_feedback.lower() != 'approve':\n",
    "        return \"create_analysts\"\n",
    "    else:\n",
    "        topic = state[\"topic\"]\n",
    "        return [\n",
    "            Send(\"conduct_interview\", {\n",
    "                \"analyst\": analyst,\n",
    "                \"messages\": [HumanMessage(content=f\"So you said you were writing an article on {topic}?\")]\n",
    "            })\n",
    "            for analyst in state[\"analysts\"]\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build main graph\n",
    "builder = StateGraph(ResearchGraphState)\n",
    "builder.add_node(\"create_analysts\", create_analysts)\n",
    "builder.add_node(\"human_feedback\", human_feedback)\n",
    "builder.add_node(\"conduct_interview\", interview_builder.compile())\n",
    "builder.add_node(\"write_report\", write_report)\n",
    "builder.add_node(\"write_introduction\", write_introduction)\n",
    "builder.add_node(\"write_conclusion\", write_conclusion)\n",
    "builder.add_node(\"write_executive_summary\", write_executive_summary)\n",
    "builder.add_node(\"finalize_report\", finalize_report)\n",
    "\n",
    "# Logic\n",
    "builder.add_edge(START, \"create_analysts\")\n",
    "builder.add_edge(\"create_analysts\", \"human_feedback\")\n",
    "builder.add_conditional_edges(\n",
    "    \"human_feedback\",\n",
    "    initiate_all_interviews,\n",
    "    [\"create_analysts\", \"conduct_interview\"]\n",
    ")\n",
    "builder.add_edge(\"conduct_interview\", \"write_report\")\n",
    "builder.add_edge(\"conduct_interview\", \"write_introduction\")\n",
    "builder.add_edge(\"conduct_interview\", \"write_conclusion\")\n",
    "builder.add_edge(\"write_report\", \"write_executive_summary\")\n",
    "builder.add_edge(\n",
    "    [\"write_conclusion\", \"write_introduction\", \"write_executive_summary\"],\n",
    "    \"finalize_report\"\n",
    ")\n",
    "builder.add_edge(\"finalize_report\", END)\n",
    "\n",
    "# Compile\n",
    "graph = builder.compile(interrupt_before=['human_feedback'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the graph\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = builder.compile(interrupt_before=['human_feedback'], checkpointer=memory)\n",
    "\n",
    "# Configuration\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start the research\n",
    "for event in graph.stream(\n",
    "    {\n",
    "        \"topic\": \"The impact of AI agents on software development\",\n",
    "        \"max_analysts\": 3,\n",
    "        \"human_analyst_feedback\": \"approve\"\n",
    "    },\n",
    "    thread,\n",
    "    stream_mode=\"values\"\n",
    "):\n",
    "    analysts = event.get('analysts', '')\n",
    "    if analysts:\n",
    "        for analyst in analysts:\n",
    "            print(f\"Name: {analyst.name}\")\n",
    "            print(f\"Role: {analyst.role}\")\n",
    "            print(f\"Description: {analyst.description}\")\n",
    "            print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approve and continue\n",
    "graph.update_state(thread, {\"human_analyst_feedback\": None}, as_node=\"human_feedback\")\n",
    "\n",
    "for event in graph.stream(None, thread, stream_mode=\"updates\"):\n",
    "    print(\"--Node--\")\n",
    "    node_name = next(iter(event.keys()))\n",
    "    print(node_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View final report\n",
    "from IPython.display import Markdown\n",
    "\n",
    "final_state = graph.get_state(thread)\n",
    "report = final_state.values.get('final_report')\n",
    "Markdown(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
